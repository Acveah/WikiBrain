{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield recall. Mute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a memory cluster, mute some nodes. See if it recalls.\n",
    "\n",
    "Mute nodes: 1) Mute half. Show recalled signal. 2) Mute the most active. Show summary\n",
    "\n",
    "If it works, can be an interesting application. Suppose you have a failure node in a network, but you need to know a signal. You can learn based on the previous signal to recover the signal of the failure node.\n",
    "\n",
    "Result: recall works even if we mute signal on a half of the nodes (including the core events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "import matplotlib.colors as colors\n",
    "from scipy import sparse\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_DATA = \"/mnt/data/git/WikiBrain/src/main/resources/hopfield/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#signal matrix (pages_ x time_)\n",
    "content = np.load(PATH_DATA + \"content.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match Wiki page ids with row numbers in <code>content</code> matrix to link it with an adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "for row in content:\n",
    "    ids.append(int(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_dict = {}\n",
    "for i, a in enumerate(ids):\n",
    "    ids_dict[a] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_dict_swap = {}\n",
    "for i, a in enumerate(ids):\n",
    "    ids_dict_swap[i] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cluster specific pages. Get rows of the content matrix specific to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHARLIE_HEBDO = '/clusters/Charlie_Hebdo_one_week_5_12_January.csv'\n",
    "GERMANWINGS = '/clusters/GermanWings_week.csv'\n",
    "\n",
    "FERGUSON_STDDEV = '/clusters/ferguson_week_stddev.csv'\n",
    "CHARLIE_STDDEV = '/clusters/charlie_week_stddev.csv'\n",
    "GERMANWINGS_STDDEV = '/clusters/germanwings_week_stddev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FERGUSON_ADJ = '/stddev/edges_ferguson.csv'\n",
    "CHARLIE_ADJ = '/stddev/edges_charlie.csv'\n",
    "GERMANWINGS_ADJ = '/stddev/edges_germanwings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABELS = FERGUSON_STDDEV\n",
    "ADJ = FERGUSON_ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(PATH_DATA + LABELS) as f:\n",
    "    cluster = f.readlines()\n",
    "cluster = [x.strip() for x in cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = map(lambda l: (int(l[0]), l[1]), map(lambda t: t.split(','), cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "printable = set(string.printable)\n",
    "cluster = map(lambda l: (int(l[0]), filter(lambda x: x in printable, l[1])), cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = dict(cluster) # (id:title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the nodes to mute\n",
    "cluster_rows = [ids_dict[pId] for pId in cluster.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read adjacency matrix and link it to content matrix. In other words, link signal to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(PATH_DATA + ADJ) as f:\n",
    "    data=[tuple(line) for line in csv.reader(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjacency for a cluster\n",
    "list_of_ids = [ids_dict_swap[x] for x in cluster_rows]\n",
    "row = [ids_dict[int(line[0])] for line in data]\n",
    "col = [ids_dict[int(line[1])] for line in data]\n",
    "data = [float(line[2]) if (float(line[2]) > 1.0 and int(line[0]) in list_of_ids and int(line[1]) in list_of_ids) else 0.0 for line in data] #learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = csr_matrix((data, (row, col)), shape=(len(ids_dict), len(ids_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = W + W.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getters by page title, row in content, and id by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(PATH_DATA + 'id_title.csv') as f:\n",
    "    data_id_title=[tuple([int(line[0]), line[1]]) for line in csv.reader(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_id_title = dict(data_id_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for example\n",
    "title = 'Je_suis_Charlie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_id = [ key for key,val in data_id_title.items() if val==title ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je_suis_Charlie'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_id_title[page_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number for page Je_suis_Charlie: 30604\n"
     ]
    }
   ],
   "source": [
    "nRow = ids_dict[page_id]\n",
    "print 'Row number for page ' + title +  \": \" + str(nRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTitleByRow(requested_row):\n",
    "    requested_id = ids_dict_swap[requested_row]\n",
    "    return data_id_title[requested_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mute some nodes in the cluster. IDs to mute are in <code>cluster_rows</code>. When mutting, assign <code>-1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mute a particular node (e.g. Charlie Hebdo 110593, Charlie Hebdo Shooting 14957, Je suis Charlie 30604)\n",
    "# content[110593] = -1\n",
    "# content[14957] = -1\n",
    "# content[30604] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# content_ = content[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mute nodes from cluster_rows\n",
    "# for row in cluster_rows[:len(cluster_rows)/2]:\n",
    "#     content[row] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O._J._Simpson_murder_case'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTitleByRow(cluster_rows[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFL cluster. Specific case. Get only team pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nfl_teams = ['Buffalo_Bills','Miami_Dolphins','New_England_Patriots','New_York_Jets','Baltimore_Ravens','Cincinnati_Bengals','Cleveland_Browns','Pittsburgh_Steelers','Houston_Texans','Indianapolis_Colts','Jacksonville_Jaguars','Tennessee_Titans','Denver_Broncos','Kansas_City_Chiefs','Los_Angeles_Chargers','Oakland_Raiders','Dallas_Cowboys','New_York_Giants','Philadelphia_Eagles','Washington_Redskins','Chicago_Bears','Detroit_Lions','Green_Bay_Packers','Minnesota_Vikings','Atlanta_Falcons','Carolina_Panthers','New_Orleans_Saints','Tampa_Bay_Buccaneers','Arizona_Cardinals','Los_Angeles_Rams','San_Francisco_49ers','Seattle_Seahawks']\n",
    "# page_ids = [ key for key,val in data_id_title.items() if val in nfl_teams ]\n",
    "# cluster_rows = [ids_dict[pID] for pID in page_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize signal (1 if active, -1 if inactive). To simplify idea of Hopfield recall process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def binarize(x):\n",
    "#     if x>0.0:\n",
    "#         x = 1.0\n",
    "#     else: x = -1.0\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binarized = np.array([[binarize(x) for x in row] for row in content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binarized_ = np.array([[binarize(x) for x in row] for row in content_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binarized = np.load(PATH_DATA + \"binarized.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binarized_ = binarized[:]\n",
    "import copy\n",
    "binarized_ = copy.copy(binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in cluster_rows[:len(cluster_rows)/2]:\n",
    "    binarized[row] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low pass filter to see trends in a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savitzky_golay(y, window_size=747, order=2, deriv=0, rate=1):\n",
    "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
    "    The Savitzky-Golay filter removes high frequency noise from data.\n",
    "    It has the advantage of preserving the original shape and\n",
    "    features of the signal better than other types of filtering\n",
    "    approaches, such as moving averages techniques.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like, shape (N,)\n",
    "        the values of the time history of the signal.\n",
    "    window_size : int\n",
    "        the length of the window. Must be an odd integer number.\n",
    "    order : int\n",
    "        the order of the polynomial used in the filtering.\n",
    "        Must be less then `window_size` - 1.\n",
    "    deriv: int\n",
    "        the order of the derivative to compute (default = 0 means only smoothing)\n",
    "    Returns\n",
    "    -------\n",
    "    ys : ndarray, shape (N)\n",
    "        the smoothed signal (or it's n-th derivative).\n",
    "    Notes\n",
    "    -----\n",
    "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
    "    suited for smoothing noisy data. The main idea behind this\n",
    "    approach is to make for each point a least-square fit with a\n",
    "    polynomial of high order over a odd-sized window centered at\n",
    "    the point.\n",
    "    Examples\n",
    "    --------\n",
    "    t = np.linspace(-4, 4, 500)\n",
    "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
    "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(t, y, label='Noisy signal')\n",
    "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
    "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
    "       Data by Simplified Least Squares Procedures. Analytical\n",
    "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
    "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
    "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
    "       Cambridge University Press ISBN-13: 9780521880688\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from math import factorial\n",
    "\n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError, msg:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# months = ['October', 'November', 'December', 'January', 'February', 'March', 'April']\n",
    "months = ['Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr']\n",
    "x_month = [i for i in np.arange(8*24, len(content[0]), 30*24)]\n",
    "x_month[1] = x_month[1] + 24 #October\n",
    "x_month[2] = x_month[2] + 24 #November\n",
    "x_month[3] = x_month[3] + 48 #December\n",
    "x_month[4] = x_month[4] + 72 #January\n",
    "x_month[5] = x_month[5] + 24 #February\n",
    "x_month[6] = x_month[6] + 48 #March\n",
    "x_month[7] = x_month[7] + 48 #April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 140, 20\n",
    "rcParams['xtick.labelsize'] = 100\n",
    "rcParams['ytick.labelsize'] = 100\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Arial']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the original signal (sum activity over pages per hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summary = np.array(csr_matrix(binarized+1).sum(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filter over 169 hours (a week) time window with a polynomial of order 2\n",
    "#month = 747 hours\n",
    "# filtered = savitzky_golay(summary[1:], window_size=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degrade signal. Flip a fraction of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def degrade(patterns,noise):\n",
    "#     #This allows you to add noise to a pattern\n",
    "#     sgn=np.vectorize(lambda x: x*-1 if np.random.random()<noise else x)\n",
    "#     out=sgn(patterns)\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#degraded = csr_matrix(degrade(np.array(binarized), 0.2))\n",
    "degraded = csr_matrix(binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r,p = degraded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(W, patterns, steps=5):\n",
    "    #The tests the network. You give it a pattern and see what it produces\n",
    "    from numpy import vectorize, dot #vector calculus functions\n",
    "    sgn = vectorize(lambda x: -1 if x<0 else +1) # convert input pattern into a -1/+1 pattern\n",
    "    for _ in xrange(steps): #over a number of iterations (defined by 'steps')    \n",
    "        print \".\" * (_ + 1)\n",
    "        patterns = W.dot(patterns) #adjust the neuron activity to reflect the weights\n",
    "        data = patterns.data\n",
    "        patterns.data = np.array([-1 if x<0 else +1 for x in data])\n",
    "    return patterns.todense() #return the final pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "recalled = recall(W/r, degraded, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if we want to plot a cluster titles\n",
    "titles = [getTitleByRow(row).decode('utf-8') for row in cluster_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a selected cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f9710387b10>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1,ax2,ax3)) = plt.subplots(1,3)\n",
    "\n",
    "axlist = [ax1,ax2,ax3]\n",
    "\n",
    "first = ax1.imshow(binarized_[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "for xc in x_month[1:7]:\n",
    "    ax1.axvline(x=xc, linewidth=1, color = 'black')\n",
    "\n",
    "    \n",
    "plt.rc('axes', titlesize=100)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=100) \n",
    "\n",
    "ax1.set_ylabel('#Page in the cluster')\n",
    "ax1.set_title('Original memory')\n",
    "    \n",
    "second = ax2.imshow(degraded.todense()[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "for xc in x_month[1:7]:\n",
    "    ax2.axvline(x=xc, linewidth=1, color = 'black')\n",
    "ax2.set_ylabel('#Page in the cluster')\n",
    "ax2.set_title('Partial memory')\n",
    "\n",
    "third = ax3.imshow(recalled[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "for xc in x_month[1:7]:\n",
    "    ax3.axvline(x=xc, linewidth=1, color = 'black')\n",
    "ax3.set_ylabel('#Page in the cluster')\n",
    "ax3.set_title('Recalled memory')\n",
    "\n",
    "pl.setp(axlist, xticks=[i + 15*24 for i in x_month], xticklabels=[month for month in months])\n",
    "\n",
    "fig.colorbar(first, ax=axlist)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.savefig(\"ferguson_recall.pdf\", format='pdf', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #original\n",
    "# # pl.figure(figsize=(100,300))\n",
    "# pl.imshow(binarized_[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month[1:-1]:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "# # pl.yticks(range(0,len(titles)), titles)\n",
    "# # pl.colorbar()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # #degraded\n",
    "# # pl.figure(figsize=(100,200))\n",
    "# # # pl.figure(figsize=(100,50))\n",
    "# # pl.imshow(degraded.todense()[nRow-10:nRow+10, :], cmap=\"Greys\", aspect='auto')\n",
    "# pl.imshow(degraded.todense()[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "# # pl.yticks(range(0,len(titles)), titles)\n",
    "# # pl.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #recalled\n",
    "# # pl.figure(figsize=(100,200))\n",
    "# # pl.figure(figsize=(100,50))\n",
    "# # pl.imshow(recalled[nRow-10:nRow+10, :], cmap=\"Greys\", aspect='auto')\n",
    "# pl.imshow(recalled[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "# # pl.yticks(range(0,len(titles)), titles)\n",
    "# # pl.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pl.figure(1)\n",
    "# pl.subplot(331)\n",
    "# pl.imshow(binarized_[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month[1:7]:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "\n",
    "# pl.subplot(332)\n",
    "# pl.imshow(degraded.todense()[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month[1:7]:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "\n",
    "# pl.subplot(333)\n",
    "# pl.imshow(recalled[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month[1:7]:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "\n",
    "\n",
    "# pl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_recalled = np.array(csr_matrix(recalled+1).sum(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_degraded = np.array(csr_matrix(degraded.todense()[cluster_rows, :]+1).sum(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_recalled = savitzky_golay(summary_recalled, window_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_degraded = savitzky_golay(summary_degraded, window_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.plot(filtered_recalled - min(filtered_recalled), 'g', label=\"Recalled\")\n",
    "pl.plot(filtered_degraded - min(filtered_degraded), 'r', label=\"Noisy\")\n",
    "# pl.plot(filtered - min(filtered), 'b', label=\"Original\")\n",
    "pl.legend()\n",
    "for xc in x_month:\n",
    "    pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "#pl.axvline(x = x_month[3] + 6*24, linewidth=5, color = 'b') #Charlie Hebdo\n",
    "#pl.axvline(x = x_month[3] + 24*24, linewidth=5, color = 'g') #Miss Universe\n",
    "#pl.axvline(x = x_month[3] + 9*24, linewidth=5, color = 'm') #Golden Globe\n",
    "pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
