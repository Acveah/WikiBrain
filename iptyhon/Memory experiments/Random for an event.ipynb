{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield recall. Random signal for nodes in an event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a memory cluster, randomize (or const) signals. See if it recalls.\n",
    "\n",
    "Signal: 1) Random in particular month. 2) Const in particular month 3) Mute everything else and try 1) and 2)\n",
    "\n",
    "If it works, can be an interesting application. Suppose you have a failure node in a network, but you need to know a signal. You can learn based on the previous signal to recover the signal of the failure node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "import matplotlib.colors as colors\n",
    "from scipy import sparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_DATA = \"/mnt/data/git/WikiBrain/src/main/resources/hopfield/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#signal matrix (pages_ x time_)\n",
    "content = np.load(PATH_DATA + \"content.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match Wiki page ids with row numbers in <code>content</code> matrix to link it with an adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "for row in content:\n",
    "    ids.append(int(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_dict = {}\n",
    "for i, a in enumerate(ids):\n",
    "    ids_dict[a] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_dict_swap = {}\n",
    "for i, a in enumerate(ids):\n",
    "    ids_dict_swap[i] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cluster specific pages. Get rows of the content matrix specific to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHARLIE_HEBDO = '/clusters/Charlie_Hebdo_one_week_5_12_January.csv'\n",
    "GERMANWINGS = '/clusters/GermanWings_week.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(PATH_DATA + CHARLIE_HEBDO) as f:\n",
    "    cluster = f.readlines()\n",
    "cluster = [x.strip() for x in cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = map(lambda l: (int(l[0]), l[1]), map(lambda t: t.split(','), cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "printable = set(string.printable)\n",
    "cluster = map(lambda l: (int(l[0]), filter(lambda x: x in printable, l[1])), cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = dict(cluster) # (id:title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the nodes to mute\n",
    "cluster_rows = [ids_dict[pId] for pId in cluster.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFL cluster. Specific case. Get only team pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nfl_teams = ['Buffalo_Bills','Miami_Dolphins','New_England_Patriots','New_York_Jets','Baltimore_Ravens','Cincinnati_Bengals','Cleveland_Browns','Pittsburgh_Steelers','Houston_Texans','Indianapolis_Colts','Jacksonville_Jaguars','Tennessee_Titans','Denver_Broncos','Kansas_City_Chiefs','Los_Angeles_Chargers','Oakland_Raiders','Dallas_Cowboys','New_York_Giants','Philadelphia_Eagles','Washington_Redskins','Chicago_Bears','Detroit_Lions','Green_Bay_Packers','Minnesota_Vikings','Atlanta_Falcons','Carolina_Panthers','New_Orleans_Saints','Tampa_Bay_Buccaneers','Arizona_Cardinals','Los_Angeles_Rams','San_Francisco_49ers','Seattle_Seahawks']\n",
    "# page_ids = [ key for key,val in data_id_title.items() if val in nfl_teams ]\n",
    "# cluster_rows = [ids_dict[pID] for pID in page_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read adjacency matrix and link it to content matrix. In other words, link signal to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(PATH_DATA + 'edges_jan_full.csv') as f:\n",
    "    data=[tuple(line) for line in csv.reader(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjacency for a cluster\n",
    "list_of_ids = [ids_dict_swap[x] for x in cluster_rows]\n",
    "row = [ids_dict[int(line[0])] for line in data]\n",
    "col = [ids_dict[int(line[1])] for line in data]\n",
    "data = [float(line[2]) if (float(line[2]) > 1.0 and int(line[0]) in list_of_ids and int(line[1]) in list_of_ids) else 0.0 for line in data] #learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = csr_matrix((data, (row, col)), shape=(len(ids_dict), len(ids_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = W + W.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getters by page title, row in content, and id by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(PATH_DATA + 'id_title.csv') as f:\n",
    "    data_id_title=[tuple([int(line[0]), line[1]]) for line in csv.reader(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_id_title = dict(data_id_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for example\n",
    "title = 'Je_suis_Charlie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_id = [ key for key,val in data_id_title.items() if val==title ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je_suis_Charlie'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_id_title[page_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number for page Je_suis_Charlie: 30604\n"
     ]
    }
   ],
   "source": [
    "nRow = ids_dict[page_id]\n",
    "print 'Row number for page ' + title +  \": \" + str(nRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTitleByRow(requested_row):\n",
    "    requested_id = ids_dict_swap[requested_row]\n",
    "    return data_id_title[requested_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mute some nodes in the cluster. IDs to mute are in <code>cluster_rows</code>. When mutting, assign <code>-1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mute a particular node (e.g. Charlie Hebdo 110593, Charlie Hebdo Shooting 14957, Je suis Charlie 30604)\n",
    "# content[110593] = -1\n",
    "# content[14957] = -1\n",
    "# content[30604] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mute nodes from cluster_rows\n",
    "for row in cluster_rows[:len(cluster_rows)/2]:\n",
    "    content[row] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getTitleByRow(cluster_rows[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize signal (1 if active, -1 if inactive). To simplify idea of Hopfield recall process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(x):\n",
    "    if x>0.0:\n",
    "        x = 1.0\n",
    "    else: x = -1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binarized = np.array([[binarize(x) for x in row] for row in content])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low pass filter to see trends in a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savitzky_golay(y, window_size=747, order=2, deriv=0, rate=1):\n",
    "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
    "    The Savitzky-Golay filter removes high frequency noise from data.\n",
    "    It has the advantage of preserving the original shape and\n",
    "    features of the signal better than other types of filtering\n",
    "    approaches, such as moving averages techniques.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like, shape (N,)\n",
    "        the values of the time history of the signal.\n",
    "    window_size : int\n",
    "        the length of the window. Must be an odd integer number.\n",
    "    order : int\n",
    "        the order of the polynomial used in the filtering.\n",
    "        Must be less then `window_size` - 1.\n",
    "    deriv: int\n",
    "        the order of the derivative to compute (default = 0 means only smoothing)\n",
    "    Returns\n",
    "    -------\n",
    "    ys : ndarray, shape (N)\n",
    "        the smoothed signal (or it's n-th derivative).\n",
    "    Notes\n",
    "    -----\n",
    "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
    "    suited for smoothing noisy data. The main idea behind this\n",
    "    approach is to make for each point a least-square fit with a\n",
    "    polynomial of high order over a odd-sized window centered at\n",
    "    the point.\n",
    "    Examples\n",
    "    --------\n",
    "    t = np.linspace(-4, 4, 500)\n",
    "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
    "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(t, y, label='Noisy signal')\n",
    "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
    "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
    "       Data by Simplified Least Squares Procedures. Analytical\n",
    "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
    "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
    "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
    "       Cambridge University Press ISBN-13: 9780521880688\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from math import factorial\n",
    "\n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError, msg:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = ['October', 'November', 'December', 'January', 'February', 'March', 'April']\n",
    "x_month = [i for i in np.arange(8*24, len(content[0]), 30*24)]\n",
    "x_month[1] = x_month[1] + 24 #October\n",
    "x_month[2] = x_month[2] + 24 #November\n",
    "x_month[3] = x_month[3] + 48 #December\n",
    "x_month[4] = x_month[4] + 72 #January\n",
    "x_month[5] = x_month[5] + 24 #February\n",
    "x_month[6] = x_month[6] + 48 #March\n",
    "x_month[7] = x_month[7] + 48 #April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 90, 40\n",
    "rcParams['xtick.labelsize'] = 50\n",
    "rcParams['ytick.labelsize'] = 50\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Arial']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the original signal (sum activity over pages per hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = np.array(csr_matrix(binarized+1).sum(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter over 169 hours (a week) time window with a polynomial of order 2\n",
    "#month = 747 hours\n",
    "filtered = savitzky_golay(summary[1:], window_size=721)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degrade signal. Flip a fraction of activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def degrade(patterns,noise):\n",
    "    #This allows you to add noise to a pattern\n",
    "    sgn=np.vectorize(lambda x: x*-1 if np.random.random()<noise else x)\n",
    "    out=sgn(patterns)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#degraded = csr_matrix(degrade(np.array(binarized), 0.2))\n",
    "degraded = csr_matrix(binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r,p = degraded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(W, patterns, steps=5):\n",
    "    #The tests the network. You give it a pattern and see what it produces\n",
    "    from numpy import vectorize, dot #vector calculus functions\n",
    "    sgn = vectorize(lambda x: -1 if x<0 else +1) # convert input pattern into a -1/+1 pattern\n",
    "    for _ in xrange(steps): #over a number of iterations (defined by 'steps')    \n",
    "        print \".\" * (_ + 1)\n",
    "        patterns = W.dot(patterns) #adjust the neuron activity to reflect the weights\n",
    "        data = patterns.data\n",
    "        patterns.data = np.array([-1 if x<0 else +1 for x in data])\n",
    "    return patterns.todense() #return the final pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recalled = recall(W/r, degraded, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if we want to plot a cluster titles\n",
    "titles = [getTitleByRow(row).decode('utf-8') for row in cluster_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a selected cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#original\n",
    "pl.figure(figsize=(100,300))\n",
    "pl.imshow(binarized[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "for xc in x_month:\n",
    "    pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "pl.yticks(range(0,len(titles)), titles)\n",
    "pl.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #degraded\n",
    "# pl.figure(figsize=(100,200))\n",
    "# # pl.figure(figsize=(100,50))\n",
    "# # pl.imshow(degraded.todense()[nRow-10:nRow+10, :], cmap=\"Greys\", aspect='auto')\n",
    "# pl.imshow(degraded.todense()[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "# for xc in x_month:\n",
    "#     pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "# pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "# pl.yticks(range(0,len(titles)), titles)\n",
    "# pl.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#recalled\n",
    "pl.figure(figsize=(100,200))\n",
    "# pl.figure(figsize=(100,50))\n",
    "# pl.imshow(recalled[nRow-10:nRow+10, :], cmap=\"Greys\", aspect='auto')\n",
    "pl.imshow(recalled[cluster_rows, :], cmap=\"Greys\", aspect='auto')\n",
    "for xc in x_month:\n",
    "    pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "pl.yticks(range(0,len(titles)), titles)\n",
    "pl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_recalled = np.array(csr_matrix(recalled+1).sum(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summary_degraded = np.array(csr_matrix(degraded.todense()+1).sum(axis = 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_recalled = savitzky_golay(summary_recalled, window_size=721)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filtered_degraded = savitzky_golay(summary_degraded, window_size=721)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.plot(summary_recalled - min(summary_recalled), 'g', label=\"Recalled\")\n",
    "# pl.plot(filtered_degraded - min(filtered_degraded), 'r', label=\"Noisy\")\n",
    "# pl.plot(filtered - min(filtered), 'b', label=\"Original\")\n",
    "pl.legend()\n",
    "for xc in x_month:\n",
    "    pl.axvline(x=xc, linewidth=1, color = 'black')\n",
    "#pl.axvline(x = x_month[3] + 6*24, linewidth=5, color = 'b') #Charlie Hebdo\n",
    "#pl.axvline(x = x_month[3] + 24*24, linewidth=5, color = 'g') #Miss Universe\n",
    "#pl.axvline(x = x_month[3] + 9*24, linewidth=5, color = 'm') #Golden Globe\n",
    "pl.xticks([i + 15*24 for i in x_month], [month for month in months])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
